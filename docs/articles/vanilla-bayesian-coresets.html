<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Vanilla Bayesian Coresets • vanillabayescoresets</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Vanilla Bayesian Coresets">
<meta property="og:description" content="vanillabayescoresets">
<meta property="og:image" content="/logo.png">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    

    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">vanillabayescoresets</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">0.1.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/vanilla-bayesian-coresets.html">Vanilla Bayesian Coresets</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Vanilla Bayesian Coresets</h1>
            
      
      
      <div class="hidden name"><code>vanilla-bayesian-coresets.Rmd</code></div>

    </div>

    
    
<style type="text/css">
  body{
  font-size: 11pt;
}
</style>
<p>This package implements <a href="https://arxiv.org/abs/1710.05053" class="external-link">Bayesian coresets</a> for binary
logistic regression data. The types of coresets that are currently
supported are the <a href="https://arxiv.org/abs/1605.06423" class="external-link">uniform
coresets</a> and the <a href="https://arxiv.org/abs/1710.05053" class="external-link">Hilbert
Frank–Wolfe coresets</a>.</p>
<p>Through vanillabayescoresets’ functions you will be able to:</p>
<ul>
<li>obtain uniform or Hilbert Frank-Wolfe coresets for binary logistic
regression data, setting the size of the coreset along with other
construction parameters.</li>
<li>plot the coreset selected over the full dataset, for the case with
two covariates, to visualize which datapoints are selected and what
weight is assigned to them by the two methods.</li>
<li>quickly generate synthetic binary data, customizing the size of the
sample, the number and the generative model of covariates and the model
parameters.</li>
</ul>
<p>This document guides you through the functionalities of this
package.</p>
<p>Let’s get started by loading the package:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va">vanillabayescoresets</span><span class="op">)</span></code></pre></div>
<div class="section level3">
<h3 id="a-little-background-first">A little background, first!<a class="anchor" aria-label="anchor" href="#a-little-background-first"></a>
</h3>
<p>Fitting Bayesian models on large datasets using standard methods such
as Markov Chain Monte Carlo can be computationally very expensive and
sometimes infeasible. Several modifications of MCMC, as well as
alternative methods like Variational Inference, have emerged to scale
inference on the full dataset. Bayesian coresets are a different
approach that achieves scalability by focusing on a pre-processing step,
aimed at delivering a small, weighted subsample of the full data on
which to run any inference algorithm.</p>
</div>
<div class="section level2">
<h2 id="sim-binary">Simulating Binary Data<a class="anchor" aria-label="anchor" href="#sim-binary"></a>
</h2>
<p>In order to apply the methods of finding coresets described by
Huggins et al. and Campbell et al., we will first need some binary data.
You can use your own binary dataset with the <a href="#uniform-coreset"><code>get_coreset_uniform()</code></a> and <a href="#hilbert-coreset"><code>get_coreset_frankwolfe()</code></a>
methods described below, or you can use our function,
<code><a href="../reference/simulate_logit_data.html">simulate_logit_data()</a></code> to easily simulate binary data that
you can use to experiment. The easiest way to use the
<code><a href="../reference/simulate_logit_data.html">simulate_logit_data()</a></code> function is to simply use the default
parameter settings and save the results to a list.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/simulate_logit_data.html">simulate_logit_data</a></span><span class="op">(</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span>
<span class="co">#&gt; [1] "y"     "x"     "theta"</span></code></pre></div>
<p>As you can see above, the function returned a list with three
elements. <code>y</code> is a vector of the binary reponses, where <span class="math inline">\(y_i \in \{-1, 1\}\)</span>, <code>x</code> is the
feature matrix, and <code>theta</code> is the vector of coefficients.
Let’s take a look at some basic properties of these objects.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">y</span><span class="op">)</span>
<span class="co">#&gt; [1] 10000</span>
<span class="fu"><a href="https://rdrr.io/r/base/dim.html" class="external-link">dim</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">x</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>
<span class="co">#&gt; [1] 10000</span>
<span class="fu"><a href="https://rdrr.io/r/base/dim.html" class="external-link">dim</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">x</span><span class="op">)</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>
<span class="co">#&gt; [1] 3</span>
<span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">theta</span><span class="op">)</span>
<span class="co">#&gt; [1] 3</span>
<span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">y</span><span class="op">)</span>
<span class="co">#&gt; [1]  1 -1  1  1 -1 -1</span></code></pre></div>
<p>Without further specification, <code>simulate_logit_data</code>
returned a <span class="math inline">\(10000 \times 1\)</span> vector
for <code>y</code>, and a <span class="math inline">\(10000 \times
3\)</span> matrix for <code>x</code>. The data are simulated using the
standard logistic regression model, i.e.</p>
<p><span class="math display">\[
\ln \left(\dfrac{p_i}{1-p_i}\right) = X\theta
\]</span> with <span class="math inline">\(p_i = Pr(y_i = 1)\)</span>,
<span class="math inline">\(Y_{nx1} = \{y_i, i = 1, ..., n\}\)</span>,
<span class="math inline">\(X_{nxd}\)</span>, and <span class="math inline">\(\theta_{dx1}\)</span>. In accordance with the
model specified in Campbell et al., the default value for
<code>theta</code> is <span class="math inline">\(\theta = (3, 3,
0)\)</span>. We can choose to further customize these specifications if
we wish.</p>
<div class="section level3">
<h3 id="dimension-specifications">Dimension specifications<a class="anchor" aria-label="anchor" href="#dimension-specifications"></a>
</h3>
<p>Most custom specifications can be included in the <code>params</code>
input parameter. For example, if you want to choose the number of
independent observations, <span class="math inline">\(n\)</span>, you
can do</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/simulate_logit_data.html">simulate_logit_data</a></span><span class="op">(</span>params <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">5000</span><span class="op">)</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">y</span><span class="op">)</span>
<span class="co">#&gt; [1] 5000</span>
<span class="fu"><a href="https://rdrr.io/r/base/dim.html" class="external-link">dim</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">x</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>
<span class="co">#&gt; [1] 5000</span></code></pre></div>
<p>which sets <span class="math inline">\(n = 5000\)</span>.</p>
<p>We can also change the number of covariates by specifying a new
vector of parameters for <span class="math inline">\(\theta\)</span></p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/simulate_logit_data.html">simulate_logit_data</a></span><span class="op">(</span>params <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">5000</span>, theta <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">2</span>, <span class="fl">3</span>, <span class="fl">4</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">theta</span><span class="op">)</span>
<span class="co">#&gt; [1] 4</span>
<span class="fu"><a href="https://rdrr.io/r/base/dim.html" class="external-link">dim</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">x</span><span class="op">)</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>
<span class="co">#&gt; [1] 4</span></code></pre></div>
<p>which sets <span class="math inline">\(\theta = (1, 2, 3,
4)\)</span>.</p>
<p>By default, <code>simulate_logit_data</code> has been sampling our
<code>x</code> values from a multivariate normal distribution with the
identity matrix as the covariance. To see this, let’s take a look at the
first few rows of <code>x</code>.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">x</span><span class="op">)</span>
<span class="co">#&gt;             [,1]       [,2]        [,3] [,4]</span>
<span class="co">#&gt; [1,]  0.66804984 -0.5219684 -0.45144751    1</span>
<span class="co">#&gt; [2,]  1.20083656  0.1510313 -0.22766468    1</span>
<span class="co">#&gt; [3,] -0.07516643  0.5121869 -0.03016629    1</span>
<span class="co">#&gt; [4,] -0.75516341 -0.5208359 -0.10085437    1</span>
<span class="co">#&gt; [5,]  0.92879962 -1.6494213 -0.60540429    1</span>
<span class="co">#&gt; [6,]  1.44734671  2.5237129  0.29886432    1</span></code></pre></div>
<p>We can further customize this generative model for
<code>x</code>.</p>
</div>
<div class="section level3">
<h3 id="model-specs">Generative model specifications<a class="anchor" aria-label="anchor" href="#model-specs"></a>
</h3>
<p>If you want to get closer to real-world data, you may want to specify
a covariance matrix with nonzero covariances. You can do this with</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">dependent_sigma</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">0.1</span>, <span class="fl">0.2</span>, <span class="fl">1</span><span class="op">)</span>, byrow <span class="op">=</span> <span class="cn">TRUE</span>, ncol <span class="op">=</span> <span class="fl">2</span>, nrow <span class="op">=</span> <span class="fl">2</span><span class="op">)</span>
<span class="va">dependent_sigma</span>
<span class="co">#&gt;      [,1] [,2]</span>
<span class="co">#&gt; [1,]  1.0  0.1</span>
<span class="co">#&gt; [2,]  0.2  1.0</span>
<span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/simulate_logit_data.html">simulate_logit_data</a></span><span class="op">(</span>params <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>sigma <span class="op">=</span> <span class="va">dependent_sigma</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<p>Instead of generating values from a normal distribution, we can also
generate binary values for <code>x</code> by specifying
<code>model = "bernoulli"</code>, e.g.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/simulate_logit_data.html">simulate_logit_data</a></span><span class="op">(</span>model <span class="op">=</span> <span class="st">"bernoulli"</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">x</span><span class="op">)</span>
<span class="co">#&gt;      [,1] [,2] [,3]</span>
<span class="co">#&gt; [1,]    1    0    1</span>
<span class="co">#&gt; [2,]    1    1    1</span>
<span class="co">#&gt; [3,]    0    1    1</span>
<span class="co">#&gt; [4,]    1    1    1</span>
<span class="co">#&gt; [5,]    1    0    1</span>
<span class="co">#&gt; [6,]    1    1    1</span></code></pre></div>
<p>We can further customize our Bernoulli model by specifying the
probability parameters for each column of <code>x</code>. This can be
done by</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/simulate_logit_data.html">simulate_logit_data</a></span><span class="op">(</span>model <span class="op">=</span> <span class="st">"bernoulli"</span>, params <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>px <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.2</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">x</span><span class="op">)</span>
<span class="co">#&gt;      [,1] [,2] [,3]</span>
<span class="co">#&gt; [1,]    0    1    1</span>
<span class="co">#&gt; [2,]    0    1    1</span>
<span class="co">#&gt; [3,]    0    1    1</span>
<span class="co">#&gt; [4,]    1    1    1</span>
<span class="co">#&gt; [5,]    0    1    1</span>
<span class="co">#&gt; [6,]    0    1    1</span></code></pre></div>
<p>where the last column is the intercept column. You can choose not to
include the intercept by setting <code>intercept = FALSE</code>.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/simulate_logit_data.html">simulate_logit_data</a></span><span class="op">(</span>model <span class="op">=</span> <span class="st">"bernoulli"</span>, 
                            params <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>theta <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">3</span>, <span class="fl">3</span><span class="op">)</span>, 
                                          px <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0.2</span>, <span class="fl">1</span><span class="op">)</span>, 
                                          intercept <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">x</span><span class="op">)</span>
<span class="co">#&gt;      [,1] [,2]</span>
<span class="co">#&gt; [1,]    1    1</span>
<span class="co">#&gt; [2,]    0    1</span>
<span class="co">#&gt; [3,]    0    1</span>
<span class="co">#&gt; [4,]    0    1</span>
<span class="co">#&gt; [5,]    0    1</span>
<span class="co">#&gt; [6,]    0    1</span></code></pre></div>
<p>Now that we have some binary data to work with, we can start looking
at methods of getting coresets.</p>
</div>
</div>
<div class="section level2">
<h2 id="uniform-coreset">Uniform Coreset Method<a class="anchor" aria-label="anchor" href="#uniform-coreset"></a>
</h2>
<p>The function <a href="#uniform-coreset"><code>get_coreset_uniform()</code></a>
implements the uniform coresets for binary logistic data, as detailed in
Algorithm 1 of <a href="https://arxiv.org/abs/1605.06423" class="external-link">J. Huggins et
al. (2016)</a>. The only inputs that are required are:</p>
<ul>
<li>
<code>x</code>: a feature matrix</li>
<li>
<code>y</code>: a binary response vector</li>
</ul>
<p>which can be from your own dataset or generated using <a href="#sim-binary"><code>simulate_logit_data()</code></a>. For example,
the code below will generate a coreset using the uniform coreset method
with all the default specifications.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/simulate_logit_data.html">simulate_logit_data</a></span><span class="op">(</span><span class="op">)</span>
<span class="va">coreset</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/get_coreset_uniform.html">get_coreset_uniform</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">x</span>, <span class="va">data</span><span class="op">$</span><span class="va">y</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">coreset</span><span class="op">$</span><span class="va">datapoints_selected</span><span class="op">)</span>
<span class="co">#&gt; [1] 692</span></code></pre></div>
<div class="section level3">
<h3 id="uniform-coreset-customizations">Uniform Coreset Customizations<a class="anchor" aria-label="anchor" href="#uniform-coreset-customizations"></a>
</h3>
<p>By default, the maximum number of observations that will be selected
for the coreset is <span class="math inline">\(\lfloor\dfrac{n}{10}\rfloor\)</span>. This can be
specified through the <code>m</code> input parameter as shown below.</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">coreset</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/get_coreset_uniform.html">get_coreset_uniform</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">x</span>, <span class="va">data</span><span class="op">$</span><span class="va">y</span>, m <span class="op">=</span> <span class="fl">500</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">coreset</span><span class="op">$</span><span class="va">datapoints_selected</span><span class="op">)</span>
<span class="co">#&gt; [1] 412</span></code></pre></div>
<p>In order to estimate each data point’s sensitivity, the function
needs to first compute a kmeans clustering of the data. The default
number of clusters is 4 (which is the number of clusters used in J.
Huggins et al.) for datasets with <span class="math inline">\(n \leq
10,000\)</span> and <span class="math inline">\(\lfloor\dfrac{n}{2500}\rfloor\)</span> for
datasets with <span class="math inline">\(n &gt; 10,000\)</span>, but
this parameter can be directly specified in the function as well.</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">coreset</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/get_coreset_uniform.html">get_coreset_uniform</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">x</span>, <span class="va">data</span><span class="op">$</span><span class="va">y</span>, num_clusters <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></code></pre></div>
<p>You can also specify a search radius <code>r</code> for the parameter
space which is set to 4 by default per the discussion in <a href="https://arxiv.org/abs/1605.06423" class="external-link">J. Huggins et al. (2016)</a>.
Lastly, because calculating coresets is not a deterministic procedure,
you can choose to set a seed so that the results of
<code><a href="../reference/get_coreset_uniform.html">get_coreset_uniform()</a></code> are reproducible given the same input
parameters, and set <code>verbose = TRUE</code> to see status messages
printed to the console.</p>
</div>
</div>
<div class="section level2">
<h2 id="hilbert-coreset">Hilbert Frank-Wolfe Coreset Method<a class="anchor" aria-label="anchor" href="#hilbert-coreset"></a>
</h2>
<p>The function <code><a href="../reference/get_coreset_frankwolfe.html">get_coreset_frankwolfe()</a></code> implements the
Hilbert Frank-Wolfe coresets for binary logistic data, as detailed in
Algorithms 2 and 3 and Sections 4.2 and 5 of <a href="https://arxiv.org/abs/1710.05053" class="external-link">T. Campbell and T. Broderick
(2019)</a>.</p>
<p>The required inputs of this function are the same as those of <a href="#uniform-coreset"><code>get_coreset_uniform()</code></a>: a matrix
<code>x</code> of covariates and a vector <code>y</code> of binary
observations in <span class="math inline">\(\{-1, 1\}\)</span>:</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/simulate_logit_data.html">simulate_logit_data</a></span><span class="op">(</span><span class="op">)</span>
<span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/glimpse.html" class="external-link">glimpse</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">x</span><span class="op">)</span>
<span class="co">#&gt;  num [1:10000, 1:3] 2.3253 -0.0395 1.7416 -0.558 -1.4288 ...</span>
<span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/glimpse.html" class="external-link">glimpse</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">y</span><span class="op">)</span>
<span class="co">#&gt;  num [1:10000] 1 1 1 -1 1 1 -1 -1 1 -1 ...</span>
<span class="va">coreset</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/get_coreset_frankwolfe.html">get_coreset_frankwolfe</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">data</span><span class="op">$</span><span class="va">x</span>, y <span class="op">=</span> <span class="va">data</span><span class="op">$</span><span class="va">y</span><span class="op">)</span>
<span class="co">#&gt; Sample Size:  10000 </span>
<span class="co">#&gt; Laplace Approximation begins...</span>
<span class="co">#&gt; Iteration:  10  of  100 ,   LP:  -2785.1 </span>
<span class="co">#&gt; Iteration:  20  of  100 ,   LP:  -2785.1 </span>
<span class="co">#&gt; Estimating the Covariance Matrix</span>
<span class="co">#&gt; Sampling from Posterior with Sampling Importance Resampling</span>
<span class="co">#&gt; Creating Summary from Point-Estimates</span>
<span class="co">#&gt; Creating Summary from Posterior Samples</span>
<span class="co">#&gt; Estimating Log of the Marginal Likelihood</span>
<span class="co">#&gt; Laplace Approximation is finished.</span></code></pre></div>
<p>The last call is equivalent to:</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">coreset</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/get_coreset_frankwolfe.html">get_coreset_frankwolfe</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">data</span><span class="op">$</span><span class="va">x</span>,
                                  y <span class="op">=</span> <span class="va">data</span><span class="op">$</span><span class="va">y</span>,
                                  m <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/integer.html" class="external-link">as.integer</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">y</span><span class="op">)</span> <span class="op">/</span> <span class="fl">10</span><span class="op">)</span>,
                                  num_projections <span class="op">=</span> <span class="fl">500</span>,
                                  seed <span class="op">=</span> <span class="fl">1234</span>,
                                  verbose <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>
<span class="co">#&gt; Sample Size:  10000 </span>
<span class="co">#&gt; Laplace Approximation begins...</span>
<span class="co">#&gt; Iteration:  10  of  100 ,   LP:  -2785.1 </span>
<span class="co">#&gt; Iteration:  20  of  100 ,   LP:  -2785.1 </span>
<span class="co">#&gt; Estimating the Covariance Matrix</span>
<span class="co">#&gt; Sampling from Posterior with Sampling Importance Resampling</span>
<span class="co">#&gt; Creating Summary from Point-Estimates</span>
<span class="co">#&gt; Creating Summary from Posterior Samples</span>
<span class="co">#&gt; Estimating Log of the Marginal Likelihood</span>
<span class="co">#&gt; Laplace Approximation is finished.</span></code></pre></div>
<p>From there, we can see what the optional parameters are and their
default values. As in <a href="#uniform-coreset"><code>get_coreset_uniform()</code></a>,
<code>m</code> controls the (maximum) number of data points included in
the coreset, and defaults to roughly one tenth of the original data
points.</p>
<p>The parameter <code>num_projections</code> is specific to the Hilbert
Frank-Wolfe method: this method requires the norm of the likelihood
gradient, whose computation is intractable, and so an approximate norm
is computed using a finite-dimensional projection of the likelihood
obtained by evaluating the likelihood at a number
<code>num_projections</code> of parameters sampled from an approximate
posterior distribution obtained through a Laplace Approximation. The
default <code>num_projections</code> is set to 500, as in the reference
paper.</p>
<p>Lastly, the parameter <code>seed</code> allows you to set a seed for
reproducibility of results and the parameter <code>verbose</code>
regulates whether messages are printed throughout the execution of the
function that inform the user on the step of the algorithm that is being
implemented (only messages printed by <a href="https://www.rdocumentation.org/packages/LaplacesDemon/versions/16.1.4/topics/LaplaceApproximation" class="external-link"><code>LaplaceApproximation()</code></a>
will be shown).</p>
<p>Note: the prior on model parameters that is currently supported is a
multivariate standard normal; the only step at which the prior is
considered is for the computation of the Laplace Approximation of the
posterior.</p>
</div>
<div class="section level2">
<h2 id="visualizing-the-coresets">Visualizing the Coresets<a class="anchor" aria-label="anchor" href="#visualizing-the-coresets"></a>
</h2>
<p>Once a coreset has been obtained, how to better appreciate the result
than with some plotting?<br>
In the current version of this package, we provide a function for
plotting the datapoints against <strong>two</strong> continuous
covariates, labeling them as either failures (i.e. y = -1) or successes
(i.e. y = 1), marking the data points selected in the coreset and
representing their weight as the point’s size.</p>
<p>The first argument required by the function
<code>visualize_coreset()</code> is an object in which the output of
either the <a href="#uniform-coreset"><code>get_coreset_uniform()</code></a> or the <a href="#hilbert-coreset"><code>get_coreset_frankwolfe()</code></a>
function has been stored. The other two required arguments are the
matrix <code>x</code> of covariates and the vector <code>y</code> of
binary observations in <span class="math inline">\(\{-1, 1\}\)</span>.
We may have to specify where the intercept column is located in matrix
of covariates (default is the third column).</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Plotting uniform coresets</span>
<span class="va">coreset_uniform</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/get_coreset_uniform.html">get_coreset_uniform</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">x</span>, <span class="va">data</span><span class="op">$</span><span class="va">y</span>, num_clusters <span class="op">=</span> <span class="fl">5</span><span class="op">)</span>
<span class="fu"><a href="../reference/visualize_coresets.html">visualize_coresets</a></span><span class="op">(</span><span class="va">coreset_uniform</span>, <span class="va">data</span><span class="op">$</span><span class="va">x</span>, <span class="va">data</span><span class="op">$</span><span class="va">y</span>, intercept_col <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></code></pre></div>
<p><img src="vanilla-bayesian-coresets_files/figure-html/unnamed-chunk-16-1.png" width="700" style="display: block; margin: auto;"></p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Plotting Hilbert Frank-Wolfe coresets</span>
<span class="va">coreset_frankwolfe</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/get_coreset_frankwolfe.html">get_coreset_frankwolfe</a></span><span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">x</span>, <span class="va">data</span><span class="op">$</span><span class="va">y</span><span class="op">)</span>
<span class="co">#&gt; Sample Size:  10000 </span>
<span class="co">#&gt; Laplace Approximation begins...</span>
<span class="co">#&gt; Iteration:  10  of  100 ,   LP:  -2785.1 </span>
<span class="co">#&gt; Iteration:  20  of  100 ,   LP:  -2785.1 </span>
<span class="co">#&gt; Estimating the Covariance Matrix</span>
<span class="co">#&gt; Sampling from Posterior with Sampling Importance Resampling</span>
<span class="co">#&gt; Creating Summary from Point-Estimates</span>
<span class="co">#&gt; Creating Summary from Posterior Samples</span>
<span class="co">#&gt; Estimating Log of the Marginal Likelihood</span>
<span class="co">#&gt; Laplace Approximation is finished.</span>
<span class="fu"><a href="../reference/visualize_coresets.html">visualize_coresets</a></span><span class="op">(</span><span class="va">coreset_frankwolfe</span>, <span class="va">data</span><span class="op">$</span><span class="va">x</span>, <span class="va">data</span><span class="op">$</span><span class="va">y</span>, intercept_col <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></code></pre></div>
<p><img src="vanilla-bayesian-coresets_files/figure-html/unnamed-chunk-17-1.png" width="700" style="display: block; margin: auto;"></p>
<p>We can customize our plot by suppressing the legend for either the
coreset point’s weight or the full-data point’s true label (or both), by
changing the axis’ labels, or by overlaying an equation line. In the
latter case, we provide as argument a vector whose first and second
elements are, respectively, the intercept and the slope of the equation
line obtained through calling <code><a href="https://rdrr.io/r/stats/glm.html" class="external-link">glm()</a></code>:</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Making optional changes</span>
<span class="va">y_glm</span> <span class="op">&lt;-</span> <span class="op">(</span><span class="va">data</span><span class="op">$</span><span class="va">y</span> <span class="op">+</span> <span class="fl">1</span><span class="op">)</span> <span class="op">/</span><span class="fl">2</span> <span class="co"># recode for glm call</span>
<span class="va">glm_estimates</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html" class="external-link">glm</a></span><span class="op">(</span><span class="va">y_glm</span> <span class="op">~</span> <span class="va">data</span><span class="op">$</span><span class="va">x</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span> <span class="op">+</span> <span class="va">data</span><span class="op">$</span><span class="va">x</span><span class="op">[</span>, <span class="fl">2</span><span class="op">]</span>, family <span class="op">=</span> <span class="st">"binomial"</span><span class="op">)</span>
<span class="va">coeffs</span> <span class="op">&lt;-</span> <span class="va">glm_estimates</span><span class="op">$</span><span class="va">coefficients</span>
<span class="va">intercept</span> <span class="op">&lt;-</span> <span class="op">-</span> <span class="va">coeffs</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">/</span> <span class="va">coeffs</span><span class="op">[</span><span class="fl">3</span><span class="op">]</span>
<span class="va">slope</span> <span class="op">&lt;-</span> <span class="op">-</span> <span class="va">coeffs</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span> <span class="op">/</span> <span class="va">coeffs</span><span class="op">[</span><span class="fl">3</span><span class="op">]</span>

<span class="fu"><a href="../reference/visualize_coresets.html">visualize_coresets</a></span><span class="op">(</span><span class="va">coreset_frankwolfe</span>, 
                   <span class="va">data</span><span class="op">$</span><span class="va">x</span>, 
                   <span class="va">data</span><span class="op">$</span><span class="va">y</span>, 
                   legend_true_label <span class="op">=</span> <span class="cn">FALSE</span>,
                   legend_weights <span class="op">=</span> <span class="cn">FALSE</span>,
                   name_variables <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"Variable 1"</span>, <span class="st">"Variable 2"</span><span class="op">)</span>,
                   equation_line <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">intercept</span>, <span class="va">slope</span><span class="op">)</span><span class="op">)</span>
<span class="co">#&gt; Warning: `guides(&lt;scale&gt; = FALSE)` is deprecated. Please use `guides(&lt;scale&gt; = "none")` instead.</span>
<span class="co">#&gt; `guides(&lt;scale&gt; = FALSE)` is deprecated. Please use `guides(&lt;scale&gt; = "none")` instead.</span></code></pre></div>
<p><img src="vanilla-bayesian-coresets_files/figure-html/unnamed-chunk-18-1.png" width="700" style="display: block; margin: auto;"></p>
<p>Now, please enjoy experimenting with Bayesian coresets!</p>
</div>
<div class="section level2">
<h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<p>The functions implemented in vanillabayescoresets (in R) are
simplified versions of some of the functions implemented in Python by
the packages <a href="https://bitbucket.org/jhhuggins/lrcoresets/src/master/coresets/" class="external-link">lrcoresets</a>
and <a href="https://github.com/trevorcampbell/bayesian-coresets" class="external-link">bayesian-coresets</a>,
created by Jonathan H. Huggins and Trevor Campbell.</p>
<p>To dive deeper into the development, the derivations, the theoretical
results and the advancements on Bayesian coresets, here is a list of
publications:</p>
<ul>
<li>J. Huggins, T. Campbell and T. Broderick, <a href="https://arxiv.org/abs/1710.05053" class="external-link">“Coresets for scalable Bayesian
logistic regression”</a> (2016)</li>
<li>T. Campbell and T. Broderick, <a href="https://arxiv.org/abs/1802.01737" class="external-link">“Bayesian coreset construction
via Greedy Iterative Geodesic Ascent”</a> (2018)</li>
<li>T. Campbell and T. Broderick, <a href="https://arxiv.org/abs/1710.05053" class="external-link">“Automated scalable Bayesian
inference via Hilbert coresets”</a> (2019)</li>
<li>T. Campbell and B. Beronov, <a href="https://arxiv.org/abs/1906.03329" class="external-link">“Sparse Variational Inference:
Bayesian Coresets from Scratch”</a> (2019)</li>
</ul>
<p>And to start gaining familiarity and intuitions on this framework,
here is a collection of some great tutorials:</p>
<ul>
<li>J. Huggins, <a href="https://www.youtube.com/watch?v=K_rjc4YMY3U" class="external-link">“Coresets for
Bayesian Logistic Regression”</a> (2016)</li>
<li>T. Broderick, <a href="https://www.youtube.com/watch?v=Moo4-KR5qNg&amp;t=5667s" class="external-link">“Variational
Bayes and Beyond: Bayesian Inference for Big Data”</a> (2018)</li>
<li>T. Campbell, <a href="https://www.youtube.com/watch?v=_8caIFEeBhY" class="external-link">“Persistent Learning
via Data Summarization”</a> (2020)</li>
</ul>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p></p>
<p>Developed by Federica Zoe Ricci, Rachel Longjohn.</p>
</div>

<div class="pkgdown">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a>
2.0.2.</p>
</div>

      </footer>
</div>

  


  

  </body>
</html>
